{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nkeriven/ensta-mt12/blob/main/notebooks/01b_knn/N2_iris_knn.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Iris Data Set](https://en.wikipedia.org/wiki/Iris_flower_data_set) Example\n",
    "\n",
    "The data set consists of $n=150$ samples from each of three species of Iris ([Iris setosa](https://en.wikipedia.org/wiki/Iris_setosa), [Iris virginica](https://en.wikipedia.org/wiki/Iris_virginica) and [Iris versicolor](https://en.wikipedia.org/wiki/Iris_versicolor),  $50$ samples from each of these three species). Four <a href=\"Feature_(machine_learning)\">features</a>, i.e. $p=4$, were measured from each sample: the length and the width of the [sepals](https://en.wikipedia.org/wiki/Sepal) and [petals](https://en.wikipedia.org/wiki/Petal), in centimetres. Based on the combination of these four features, a classification task is to distinguish the species from each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "Several conventional data set, such as the well known *Iris* data set. are included in the Sickit-learn toolbox. The first axis (lines) is the samples and the second axis is the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 150 samples with 4 features. We can plot the data for some pairs of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "f,((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(16, 12))\n",
    "# Axe 1 and 2\n",
    "ax1.scatter(data[:,0], data[:,1],c=iris.target,)\n",
    "ax1.set_xlabel(iris.feature_names[0])\n",
    "ax1.set_ylabel(iris.feature_names[1])\n",
    "\n",
    "# Axe 1 and 3\n",
    "ax2.scatter(data[:,0], data[:,2],c=iris.target,)\n",
    "ax2.set_xlabel(iris.feature_names[0])\n",
    "ax2.set_ylabel(iris.feature_names[2])\n",
    "\n",
    "# Axe 2 and 4\n",
    "ax3.scatter(data[:,1], data[:,3],c=iris.target,)\n",
    "ax3.set_xlabel(iris.feature_names[1])\n",
    "ax3.set_ylabel(iris.feature_names[3])\n",
    "\n",
    "# Axe 3 and 4\n",
    "ax4.scatter(data[:,2], data[:,3],c=iris.target,)\n",
    "ax4.set_xlabel(iris.feature_names[2])\n",
    "ax4.set_ylabel(iris.feature_names[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning\n",
    "\n",
    "The problem is to learn a function linking the observation (here *data*) and the external data (here *target*). With scikit-learn, we need to select one alorithm then apply the *fit* method and the *predict* method. Using a K-Nearest Neighbors classifiers, it reduces to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier() # Creation of the classifier\n",
    "knn.fit(iris.data, iris.target) # Model fitting\n",
    "y_predict = knn.predict(iris.data) # Prediction\n",
    "\n",
    "print(y_predict[::10])\n",
    "print(iris.target[::10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, easy. But in practice we never do that: we should fit and predict with different samples! In fact, we have seen that training error is a (sometimes very) optimistically biased estimation of the true error rate of our algorithm. We need to split the data set into a training set and a validation set. Hopefully, scikit-learn provides a set of tools to manipulate the data. Furthermore, since the *fit* and the *predict* function are always the same whatever the algorithm, benchmarking using scikit-learn is super easy.\n",
    "\n",
    "Here we are comparing several standard classifiers (note that, at this time, we apply them as 'black boxes', but we will see the details later in the course) using the universal functions `fit` and `predict` provided by scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model, svm\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score # accuracy = rate of correct classification\n",
    "\n",
    "# Init classifier\n",
    "classifiers = [LinearDiscriminantAnalysis(solver=\"lsqr\"), QuadraticDiscriminantAnalysis(),\n",
    "               linear_model.LogisticRegression(solver='lbfgs',multi_class='multinomial'),svm.SVC(kernel='linear'), KNeighborsClassifier()]\n",
    "names = [\"LDA\", \"QDA\", \"Logistic Regression\", \"Support Vector Machines\", \"K Nearest Neighbors\"]\n",
    "\n",
    "# Split data -> 1/2 for learning & 1/2 for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.5, random_state=0)\n",
    "\n",
    "for clf,name in zip(classifiers,names):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test) # predict the label of X_test from X_train and y_train\n",
    "    mcr_error = 1-accuracy_score(y_test, y_pred) # Compute the overall misclassification rate\n",
    "    print('Errors for {1}: \\t {0:.2f}'.format(mcr_error,name)) # \\t means \"tabular\" space, and {0:.2f} \n",
    "                                                           # means we print only two first decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model complexity\n",
    "Each algorithm has a set of hyperparameters that needs to be optimized for the considered data set. This issue will be addressed later. Here, we just illustrate the fact that they could have a great influence on the final decision.\n",
    "\n",
    "For the KNN, the number of neighbors considered for the decision is the main hyperparemeter to set-up for small to medium size problem. Default value for scikit-learn is set to 5 (do knn? for help). In the following we are going to plot the overall misclassication rate function of the hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.arange(1,25)\n",
    "errors_train, errors_validation = [], []\n",
    "for n_ in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knn.predict(X_train)\n",
    "    errors_train.append(1-accuracy_score(y_train, y_pred))\n",
    "    \n",
    "    y_pred = knn.predict(X_test)\n",
    "    errors_validation.append(1-accuracy_score(y_test, y_pred))\n",
    "    \n",
    "plt.plot(neighbors,errors_train)\n",
    "plt.plot(neighbors,errors_validation)\n",
    "plt.legend([\"Train\", \"Test\"])\n",
    "plt.xlabel(\"Number of neighbors\")\n",
    "plt.ylabel(\"Misclassification rate\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "- What is the (estimated) optimal value for the knn parameter?\n",
    "- What is the optimal error rate?\n",
    "- Replace the defaut euclidean metric used to determine the nearest neighbors by [\"chebyshev\" one](https://en.wikipedia.org/wiki/Chebyshev_distance) (also called L infinity) and compare your results (*hint:* see the parameter `metric` of [`KNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)).\n",
    "- What happens when we change the test and train sets (e.g., try on several runs by changing the `random_state` seed)? \n",
    "- How confident are you on these best scores/hyperparameter values?\n",
    "\n",
    "We will see later how to apply more efficient procedures to assess the model performances or to tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
