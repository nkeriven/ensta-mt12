{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nkeriven/ensta-mt12/blob/main/notebooks/01c_model_assessment/N1_validation_and_model_selection.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Validation\n",
    "In this notebook, we will apply and optimize several algorithms on the *Digits* dataset. This is used to illustrate  cross validation principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$ fold Cross Validation Algorithm\n",
    "\n",
    "`Input`: input variables $X$ (dimension $n \\times p$), responses $y$ (dimension n), number of folds $k$\n",
    "\n",
    "`Divide` randomly the set $\\{1, 2, ..., n\\}$ in $k$ subsets (i.e., folds) of roughly equal sizes (e.g., size equals to the integer part of $n/k$ with a little smaller last part if $n$ is not a multiple of $k$) denoted as $F_1,\\ldots,F_{k}$\n",
    "\n",
    "`for i=1 to k:`\n",
    "  * `Form` the validation set $(X_{val}, y_{val})$ where the indexes of the $X$ and $y$ variables belongs to the $i$th fold $F_i$\n",
    "  * `Form` the training set $(X_{train}, y_{train})$  where the indexes of the $X$ and $y$ variables belongs to all the folds except $F_i$\n",
    "  * `Train` the algorithm/model on the training set $(X_{train}, y_{train})$\n",
    "  * `Apply` the resulting prediction rule on the input  $X_{val}$ of the validation set\n",
    "  * `Compute` the error rate on the validation set based on the predictions and the true responses $y_{val}$\n",
    "\n",
    "`Output`: the average error rate computed over all the $k$ folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits, load_iris\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Load digits\n",
    "X, y = load_digits(return_X_y=True) # load_iris(return_X_y=True)\n",
    "print(X.shape)\n",
    "print(X.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualization of the digits data set\n",
    "The data set is made available *by NIST to extract normalized bitmaps of handwritten digits from a preprinted form. From a total of 43 people, 30 contributed to the training set and different 13 to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of 4x4 and the number of on pixels are counted in each block. This generates an input matrix of 8x8 where each element is an integer in the range 0..16* (https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits)\n",
    "\n",
    "It is possible to visualize the data by reshaping correctly each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the first element\n",
    "plt.figure(figsize=(10,5) )\n",
    "plt.subplot(2, 5, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow(X[0,:].reshape(8,8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.title(\"Label = {}\".format(y[0]))\n",
    "\n",
    "# Plot the hundredth element\n",
    "ith= 100\n",
    "for ith in range(100,109):\n",
    "    plt.subplot(2, 5, ith-98)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X[ith,:].reshape(8,8), plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title(\"Label = {}\".format(y[ith]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification framework\n",
    "Two steps are required\n",
    "- Model selection, i.e. find the optimal hyperparemeters,\n",
    "- Model assessement, i.e. validate the model on unseen data.\n",
    "\n",
    "As said in introduction, scikit-learn offers convenient and generic functions to achieve these steps.  In this labworks, an example is given for the nearest-neighbors classifier (KNeighborsClassifier) (http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). But it can be extended for any algorithm in scikit-learn, up to a correct definition of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Standardize data\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X) # Scale data between 0 and 1\n",
    "\n",
    "# Split the data -> test_size=0.20 means we keep 80% of the data for training and 20% for validation\n",
    "# The stratification ensures that the proportion of each class from the orginal data is preserved in the train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With distance based methods (s.t. k-NN or kernel methods), it is a good practice to standardize feature remove dynamics effect. Here we rescaled each feature between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html) strategy to select the optimal set of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the correct classification rate function of the hyperparameters. It is important to check if our search values are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of k-NN classifier\n",
    "Again, using scikit-learn generic function, it is possible with few lines of code to run all the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "score = 'accuracy' #correct classification rate\n",
    "param_grid = {'n_neighbors':[1, 3, 5, 7, 9, 11, 13, 15]}\n",
    "\n",
    "clf = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv= 5, scoring=score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.best_estimator_  \n",
    "    \n",
    "print(\"Results for the cross-validation:\")\n",
    "print( clf.best_params_ )\n",
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], # score moyen\n",
    "clf.cv_results_['std_test_score'], # écart-type du score\n",
    "clf.cv_results_['params'] # valeur de l'hyperparamètre\n",
    "):\n",
    "    print(\"\\t%s = %0.3f (+/-%0.03f) for %r\" % (score, # critère utilisé\n",
    "                                            mean, # score moyen\n",
    "                                            std * 2, # barre d'erreur\n",
    "                                            params # hyperparamètre\n",
    "                                            ) )\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"\\nResults for the Test data set: %0.3f\" % accuracy_score(y_test, y_pred) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Display some classification errors \n",
    "t = np.where(y_pred!=y_test)[0]\n",
    "plt.figure(figsize=(10,5) )\n",
    "for i, t_ in enumerate(t[:10]):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_test[t_,:].reshape(8,8), cmap=plt.cm.gray_r)\n",
    "    plt.title(\"Label = {} Pred = {}\".format(y_test[t_],y_pred[t_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "- Recall what are the benefits of cross-validation w.r.t the simple validation approach\n",
    "- Apply the same CV procedure to the iris data set (see  and adapt notebook \n",
    "[`2_knn/N2_iris_knn.ipynb`](https://gricad-gitlab.univ-grenoble-alpes.fr/chatelaf/ml-sicom3a/-/blob/master/notebooks/2_knn/N2_iris_knn.ipynb)). Compare your results with the simple validation approach (fixed training and test set) used in [`2_knn/N2_iris_knn.ipynb`](https://gricad-gitlab.univ-grenoble-alpes.fr/chatelaf/ml-sicom3a/-/blob/master/notebooks/2_knn/N2_iris_knn.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
