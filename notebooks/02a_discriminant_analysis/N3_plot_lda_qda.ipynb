{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nkeriven/ensta-mt12/blob/main/notebooks/03_discriminant_analysis/N3_plot_lda_qda.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Linear and Quadratic Discriminant Analysis with covariance ellipsoid\n",
    "\n",
    "\n",
    "This example plots the covariance ellipsoids of each class and\n",
    "decision boundary learned by LDA and QDA. The ellipsoids display\n",
    "the double standard deviation for each class. With LDA, the\n",
    "standard deviation is the same for all the classes, while each\n",
    "class has its own standard deviation with QDA model.\n",
    "\n",
    "*taken from scikit-learn*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# #############################################################################\n",
    "# Colormap\n",
    "cmap = colors.LinearSegmentedColormap(\n",
    "    'red_blue_classes',\n",
    "    {'red': [(0, 1, 1), (1, 0.7, 0.7)],\n",
    "     'green': [(0, 0.7, 0.7), (1, 0.7, 0.7)],\n",
    "     'blue': [(0, 0.7, 0.7), (1, 1, 1)]})\n",
    "plt.cm.register_cmap(cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Generate datasets\n",
    "def dataset_fixed_cov():\n",
    "    '''Generate 2 Gaussians samples with the same covariance matrix'''\n",
    "    n, dim = 300, 2\n",
    "    np.random.seed(0)\n",
    "    C = np.array([[0., -0.23], [0.83, .23]])\n",
    "    X = np.r_[np.dot(np.random.randn(n, dim), C),\n",
    "              np.dot(np.random.randn(n, dim), C) + np.array([1, 1])]\n",
    "    y = np.hstack((np.zeros(n), np.ones(n)))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def dataset_cov():\n",
    "    '''Generate 2 Gaussians samples with different covariance matrices'''\n",
    "    n, dim = 300, 2\n",
    "    np.random.seed(0)\n",
    "    C = np.array([[0., -1.], [2.5, .7]]) * 2.\n",
    "    X = np.r_[np.dot(np.random.randn(n, dim), C),\n",
    "              np.dot(np.random.randn(n, dim), C.T) + np.array([1, 4])]\n",
    "    y = np.hstack((np.zeros(n), np.ones(n)))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# Plot functions\n",
    "def plot_data(lda, X, y, y_pred, fig_index):\n",
    "    splot = plt.subplot(2, 2, fig_index)\n",
    "    if fig_index == 1:\n",
    "        plt.title('Linear Discriminant Analysis')\n",
    "        plt.ylabel('Data with\\n fixed covariance')\n",
    "    elif fig_index == 2:\n",
    "        plt.title('Quadratic Discriminant Analysis')\n",
    "    elif fig_index == 3:\n",
    "        plt.ylabel('Data with\\n varying covariances')\n",
    "\n",
    "    tp = (y == y_pred)  # True Positive\n",
    "    tp0, tp1 = tp[y == 0], tp[y == 1]\n",
    "    X0, X1 = X[y == 0], X[y == 1]\n",
    "    X0_tp, X0_fp = X0[tp0], X0[~tp0]\n",
    "    X1_tp, X1_fp = X1[tp1], X1[~tp1]\n",
    "\n",
    "    # class 0: dots\n",
    "    plt.scatter(X0_tp[:, 0], X0_tp[:, 1], marker='.', color='red')\n",
    "    plt.scatter(X0_fp[:, 0], X0_fp[:, 1], marker='x',\n",
    "                s=20, color='#990000')  # dark red\n",
    "\n",
    "    # class 1: dots\n",
    "    plt.scatter(X1_tp[:, 0], X1_tp[:, 1], marker='.', color='blue')\n",
    "    plt.scatter(X1_fp[:, 0], X1_fp[:, 1], marker='x',\n",
    "                s=20, color='#000099')  # dark blue\n",
    "\n",
    "    # class 0 and 1 : areas\n",
    "    nx, ny = 200, 100\n",
    "    x_min, x_max = plt.xlim()\n",
    "    y_min, y_max = plt.ylim()\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx),\n",
    "                         np.linspace(y_min, y_max, ny))\n",
    "    Z = lda.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z[:, 1].reshape(xx.shape)\n",
    "    plt.pcolormesh(xx, yy, Z, cmap='red_blue_classes',\n",
    "                   norm=colors.Normalize(0., 1.), zorder=0)\n",
    "    plt.contour(xx, yy, Z, [0.5], linewidths=2., colors='white')\n",
    "\n",
    "    # means\n",
    "    plt.plot(lda.means_[0][0], lda.means_[0][1],\n",
    "             '*', color='yellow', markersize=15, markeredgecolor='grey')\n",
    "    plt.plot(lda.means_[1][0], lda.means_[1][1],\n",
    "             '*', color='yellow', markersize=15, markeredgecolor='grey')\n",
    "\n",
    "    return splot\n",
    "\n",
    "\n",
    "def plot_ellipse(splot, mean, cov, color):\n",
    "    v, w = linalg.eigh(cov)\n",
    "    u = w[0] / linalg.norm(w[0])\n",
    "    angle = np.arctan(u[1] / u[0])\n",
    "    angle = 180 * angle / np.pi  # convert to degrees\n",
    "    # filled Gaussian at 2 standard deviation\n",
    "    ell = mpl.patches.Ellipse(mean, 2 * v[0] ** 0.5, 2 * v[1] ** 0.5,\n",
    "                              180 + angle, facecolor=color,\n",
    "                              edgecolor='black', linewidth=2)\n",
    "    ell.set_clip_box(splot.bbox)\n",
    "    ell.set_alpha(0.2)\n",
    "    splot.add_artist(ell)\n",
    "    splot.set_xticks(())\n",
    "    splot.set_yticks(())\n",
    "\n",
    "\n",
    "def plot_lda_cov(lda, splot):\n",
    "    plot_ellipse(splot, lda.means_[0], lda.covariance_, 'red')\n",
    "    plot_ellipse(splot, lda.means_[1], lda.covariance_, 'blue')\n",
    "\n",
    "\n",
    "def plot_qda_cov(qda, splot):\n",
    "    plot_ellipse(splot, qda.means_[0], qda.covariance_[0], 'red')\n",
    "    plot_ellipse(splot, qda.means_[1], qda.covariance_[1], 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8), facecolor='white')\n",
    "plt.suptitle('Linear Discriminant Analysis vs Quadratic Discriminant Analysis',\n",
    "             y=0.98, fontsize=15)\n",
    "for i, (X, y) in enumerate([dataset_fixed_cov(), dataset_cov()]):\n",
    "    # Linear Discriminant Analysis\n",
    "    lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "    y_pred = lda.fit(X, y).predict(X)\n",
    "    splot = plot_data(lda, X, y, y_pred, fig_index=2 * i + 1)\n",
    "    plot_lda_cov(lda, splot)\n",
    "    plt.axis('tight')\n",
    "\n",
    "    # Quadratic Discriminant Analysis\n",
    "    qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "    y_pred = qda.fit(X, y).predict(X)\n",
    "    splot = plot_data(qda, X, y, y_pred, fig_index=2 * i + 2)\n",
    "    plot_qda_cov(qda, splot)\n",
    "    plt.axis('tight')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "- Which model (LDA or QDA) should be preferred in the first example (first row)?\n",
    "- What kind of functions define the decision boudary for QDA in the second example (second row)? Is this boudary in agreement with the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
